"""
ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu y t·∫ø ƒë√£ thu th·∫≠p
T·∫°o b√°o c√°o chi ti·∫øt v·ªÅ ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu
"""
import json
import re
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from collections import Counter
import pandas as pd
from loguru import logger
from datetime import datetime
import sys

sys.path.append(str(Path(__file__).parent.parent.parent))
from src.config import (
    RAW_DATA_DIR, PROCESSED_DATA_DIR, GENERATED_DATA_DIR, 
    EXTERNAL_DATA_DIR, BASE_DIR
)


class DataQualityEvaluator:
    """ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu y t·∫ø"""
    
    def __init__(self):
        self.quality_report = {
            'overview': {},
            'by_category': {},
            'by_source': {},
            'issues': [],
            'recommendations': []
        }
    
    def load_all_data(self) -> Dict[str, List[Dict]]:
        """Load t·∫•t c·∫£ d·ªØ li·ªáu t·ª´ c√°c ngu·ªìn"""
        data = {
            'raw': [],
            'processed': [],
            'generated': [],
            'external': []
        }
        
        # Raw data
        for category_dir in RAW_DATA_DIR.glob("*/"):
            for json_file in category_dir.glob("*.json"):
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        file_data = json.load(f)
                    if isinstance(file_data, list):
                        data['raw'].extend(file_data)
                    else:
                        data['raw'].append(file_data)
                except Exception as e:
                    logger.warning(f"Error loading {json_file}: {e}")
        
        # Processed data
        processed_file = PROCESSED_DATA_DIR / "all_processed_data.json"
        if processed_file.exists():
            try:
                with open(processed_file, 'r', encoding='utf-8') as f:
                    loaded = json.load(f)
                if 'data' in loaded:
                    data['processed'] = loaded['data']
                else:
                    data['processed'] = loaded if isinstance(loaded, list) else [loaded]
            except Exception as e:
                logger.warning(f"Error loading processed data: {e}")
        
        # Generated QA data
        for json_file in GENERATED_DATA_DIR.glob("*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    file_data = json.load(f)
                if 'data' in file_data:
                    data['generated'].extend(file_data['data'])
                elif isinstance(file_data, list):
                    data['generated'].extend(file_data)
            except Exception as e:
                logger.warning(f"Error loading {json_file}: {e}")
        
        # External data
        for json_file in EXTERNAL_DATA_DIR.glob("*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    file_data = json.load(f)
                if isinstance(file_data, list):
                    data['external'].extend(file_data)
            except Exception as e:
                logger.warning(f"Error loading {json_file}: {e}")
        
        return data
    
    def check_completeness(self, item: Dict, required_fields: List[str]) -> Dict:
        """Ki·ªÉm tra t√≠nh ƒë·∫ßy ƒë·ªß c·ªßa m·ªôt record"""
        result = {
            'complete': True,
            'missing_fields': [],
            'empty_fields': []
        }
        
        for field in required_fields:
            if field not in item:
                result['missing_fields'].append(field)
                result['complete'] = False
            elif not item[field]:
                result['empty_fields'].append(field)
                result['complete'] = False
        
        return result
    
    def check_text_quality(self, text: str) -> Dict:
        """Ki·ªÉm tra ch·∫•t l∆∞·ª£ng c·ªßa text"""
        if not text:
            return {'quality': 'empty', 'score': 0, 'issues': ['Empty text']}
        
        issues = []
        score = 100
        
        # Ki·ªÉm tra ƒë·ªô d√†i
        if len(text) < 20:
            issues.append('Too short')
            score -= 20
        
        # Ki·ªÉm tra HTML c√≤n s√≥t
        if re.search(r'<[^>]+>', text):
            issues.append('Contains HTML')
            score -= 15
        
        # Ki·ªÉm tra URL
        if re.search(r'http[s]?://', text):
            issues.append('Contains URLs')
            score -= 10
        
        # Ki·ªÉm tra k√Ω t·ª± l·∫°
        special_chars = len(re.findall(r'[^\w\s√†√°·∫£√£·∫°ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√¢·∫ß·∫•·∫©·∫´·∫≠ƒë√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµ.,;:?!-]', text, re.UNICODE))
        if special_chars > len(text) * 0.1:
            issues.append('Many special characters')
            score -= 15
        
        # Ki·ªÉm tra l·∫∑p t·ª´
        words = text.lower().split()
        if words:
            word_counts = Counter(words)
            most_common = word_counts.most_common(1)[0]
            if most_common[1] > len(words) * 0.3:
                issues.append('Repetitive content')
                score -= 20
        
        # X√°c ƒë·ªãnh quality level
        if score >= 80:
            quality = 'high'
        elif score >= 60:
            quality = 'medium'
        elif score >= 40:
            quality = 'low'
        else:
            quality = 'poor'
        
        return {
            'quality': quality,
            'score': max(0, score),
            'issues': issues,
            'length': len(text)
        }
    
    def evaluate_medical_content(self, text: str) -> Dict:
        """ƒê√°nh gi√° n·ªôi dung y t·∫ø"""
        if not text:
            return {'is_medical': False, 'confidence': 0}
        
        text_lower = text.lower()
        
        # T·ª´ kh√≥a y t·∫ø
        medical_keywords = [
            'b·ªánh', 'tri·ªáu ch·ª©ng', 'thu·ªëc', 'ƒëi·ªÅu tr·ªã', 'ch·∫©n ƒëo√°n',
            'nguy√™n nh√¢n', 'ph√≤ng ng·ª´a', 'x√©t nghi·ªám', 'virus', 'vi khu·∫©n',
            'vi√™m', 'nhi·ªÖm', 'ƒëau', 's·ªët', 'ho', 'ung th∆∞', 'tim m·∫°ch',
            'huy·∫øt √°p', 'ƒë∆∞·ªùng huy·∫øt', 'vaccine', 'kh√°ng sinh', 'd·ªã ·ª©ng',
            'ph·∫´u thu·∫≠t', 'li·ªÅu d√πng', 't√°c d·ª•ng ph·ª•', 'ch·ªëng ch·ªâ ƒë·ªãnh'
        ]
        
        # ƒê·∫øm t·ª´ kh√≥a y t·∫ø
        keyword_count = sum(1 for kw in medical_keywords if kw in text_lower)
        
        # T√≠nh confidence
        confidence = min(100, keyword_count * 10)
        
        return {
            'is_medical': keyword_count >= 2,
            'confidence': confidence,
            'keyword_count': keyword_count
        }
    
    def evaluate_qa_quality(self, qa_data: List[Dict]) -> Dict:
        """ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu Q&A"""
        if not qa_data:
            return {'total': 0, 'quality': 'N/A'}
        
        stats = {
            'total': len(qa_data),
            'true_count': 0,
            'false_count': 0,
            'with_explanation': 0,
            'valid_format': 0,
            'avg_question_length': 0,
            'quality_scores': []
        }
        
        question_lengths = []
        
        for qa in qa_data:
            # ƒê·∫øm True/False
            answer = qa.get('answer', '').strip()
            if answer in ['ƒê√∫ng', 'True', 'ƒë√∫ng', 'true']:
                stats['true_count'] += 1
            elif answer in ['Sai', 'False', 'sai', 'false']:
                stats['false_count'] += 1
            
            # C√≥ explanation?
            if qa.get('explanation'):
                stats['with_explanation'] += 1
            
            # Format h·ª£p l·ªá?
            if qa.get('question') and qa.get('answer'):
                stats['valid_format'] += 1
            
            # ƒê·ªô d√†i c√¢u h·ªèi
            question = qa.get('question', '')
            if question:
                question_lengths.append(len(question))
                
                # ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng c√¢u h·ªèi
                q_quality = self.check_text_quality(question)
                stats['quality_scores'].append(q_quality['score'])
        
        if question_lengths:
            stats['avg_question_length'] = sum(question_lengths) / len(question_lengths)
        
        if stats['quality_scores']:
            stats['avg_quality_score'] = sum(stats['quality_scores']) / len(stats['quality_scores'])
        
        # Balance ratio
        if stats['true_count'] + stats['false_count'] > 0:
            balance = min(stats['true_count'], stats['false_count']) / max(stats['true_count'], stats['false_count'])
            stats['balance_ratio'] = round(balance, 2)
        
        return stats
    
    def generate_report(self) -> Dict:
        """T·∫°o b√°o c√°o ƒë·∫ßy ƒë·ªß v·ªÅ ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu"""
        logger.info("Loading all data...")
        all_data = self.load_all_data()
        
        # Overview statistics
        self.quality_report['overview'] = {
            'total_raw': len(all_data['raw']),
            'total_processed': len(all_data['processed']),
            'total_generated_qa': len(all_data['generated']),
            'total_external': len(all_data['external']),
            'total_all': sum(len(v) for v in all_data.values()),
            'evaluation_date': datetime.now().isoformat()
        }
        
        # Evaluate raw data quality
        logger.info("Evaluating raw data quality...")
        raw_quality = {
            'high': 0, 'medium': 0, 'low': 0, 'poor': 0,
            'medical_content': 0,
            'issues': Counter()
        }
        
        for item in all_data['raw']:
            # Check main content
            content = item.get('content', '') or item.get('description', '')
            quality = self.check_text_quality(content)
            raw_quality[quality['quality']] += 1
            
            for issue in quality['issues']:
                raw_quality['issues'][issue] += 1
            
            # Check medical relevance
            medical = self.evaluate_medical_content(content)
            if medical['is_medical']:
                raw_quality['medical_content'] += 1
        
        raw_quality['issues'] = dict(raw_quality['issues'].most_common(10))
        self.quality_report['raw_data_quality'] = raw_quality
        
        # Evaluate QA data
        logger.info("Evaluating QA data quality...")
        qa_stats = self.evaluate_qa_quality(all_data['generated'])
        self.quality_report['qa_data_quality'] = qa_stats
        
        # Evaluate by source
        logger.info("Evaluating by source...")
        source_stats = {}
        for item in all_data['raw']:
            source = item.get('source', 'unknown')
            if source not in source_stats:
                source_stats[source] = {'count': 0, 'high_quality': 0}
            source_stats[source]['count'] += 1
            
            content = item.get('content', '') or item.get('description', '')
            if self.check_text_quality(content)['score'] >= 70:
                source_stats[source]['high_quality'] += 1
        
        # Calculate quality percentage per source
        for source, stats in source_stats.items():
            if stats['count'] > 0:
                stats['quality_percent'] = round(stats['high_quality'] / stats['count'] * 100, 1)
        
        self.quality_report['by_source'] = source_stats
        
        # Evaluate external data
        logger.info("Evaluating external data...")
        external_stats = {
            'total': len(all_data['external']),
            'with_vietnamese': 0,
            'sources': Counter()
        }
        
        for item in all_data['external']:
            if item.get('term_vi') or item.get('name_vi') or item.get('definition_vi'):
                external_stats['with_vietnamese'] += 1
            external_stats['sources'][item.get('source', 'unknown')] += 1
        
        external_stats['sources'] = dict(external_stats['sources'])
        self.quality_report['external_data'] = external_stats
        
        # Identify issues and recommendations
        self._identify_issues()
        self._generate_recommendations()
        
        return self.quality_report
    
    def _identify_issues(self):
        """X√°c ƒë·ªãnh c√°c v·∫•n ƒë·ªÅ v·ªÅ ch·∫•t l∆∞·ª£ng"""
        issues = []
        
        # Check data volume
        total = self.quality_report['overview']['total_all']
        if total < 50000:
            issues.append({
                'type': 'volume',
                'severity': 'high',
                'message': f'Ch∆∞a ƒë·ªß 50,000 d·ªØ li·ªáu (hi·ªán c√≥ {total})',
                'suggestion': 'C·∫ßn crawl th√™m d·ªØ li·ªáu ho·∫∑c sinh th√™m t·ª´ LLM'
            })
        
        # Check quality distribution
        raw_quality = self.quality_report.get('raw_data_quality', {})
        poor_ratio = raw_quality.get('poor', 0) + raw_quality.get('low', 0)
        total_raw = self.quality_report['overview']['total_raw']
        
        if total_raw > 0 and poor_ratio / total_raw > 0.3:
            issues.append({
                'type': 'quality',
                'severity': 'medium',
                'message': f'{poor_ratio} records c√≥ ch·∫•t l∆∞·ª£ng th·∫•p ({poor_ratio/total_raw*100:.1f}%)',
                'suggestion': 'C·∫ßn c·∫£i thi·ªán pipeline ti·ªÅn x·ª≠ l√Ω'
            })
        
        # Check QA balance
        qa_stats = self.quality_report.get('qa_data_quality', {})
        if qa_stats.get('balance_ratio', 1) < 0.7:
            issues.append({
                'type': 'balance',
                'severity': 'medium',
                'message': 'D·ªØ li·ªáu Q&A kh√¥ng c√¢n b·∫±ng gi·ªØa ƒê√∫ng/Sai',
                'suggestion': 'C·∫ßn sinh th√™m c√¢u h·ªèi cho class thi·∫øu'
            })
        
        self.quality_report['issues'] = issues
    
    def _generate_recommendations(self):
        """Sinh c√°c khuy·∫øn ngh·ªã c·∫£i thi·ªán"""
        recommendations = []
        
        # Based on overview
        overview = self.quality_report['overview']
        
        if overview['total_external'] < 100:
            recommendations.append(
                "N√™n tƒÉng c∆∞·ªùng s·ª≠ d·ª•ng ngu·ªìn d·ªØ li·ªáu qu·ªëc t·∫ø (UMLS, ICD-10, MeSH) ƒë·ªÉ ƒë∆∞·ª£c ƒëi·ªÉm c·ªông"
            )
        
        if overview['total_generated_qa'] < 10000:
            recommendations.append(
                "N√™n sinh th√™m c√¢u h·ªèi Q&A ƒë·ªÉ ƒë·∫°t y√™u c·∫ßu s·ªë l∆∞·ª£ng"
            )
        
        # Based on source quality
        source_stats = self.quality_report.get('by_source', {})
        low_quality_sources = [
            src for src, stats in source_stats.items() 
            if stats.get('quality_percent', 0) < 50
        ]
        
        if low_quality_sources:
            recommendations.append(
                f"C·∫ßn c·∫£i thi·ªán x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ c√°c ngu·ªìn: {', '.join(low_quality_sources)}"
            )
        
        self.quality_report['recommendations'] = recommendations
    
    def save_report(self, filename: str = "data_quality_report.json"):
        """L∆∞u b√°o c√°o"""
        output_file = BASE_DIR / "reports" / filename
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.quality_report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Report saved to {output_file}")
        
        # C≈©ng t·∫°o report markdown
        md_report = self._generate_markdown_report()
        md_file = output_file.with_suffix('.md')
        
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(md_report)
        
        logger.info(f"Markdown report saved to {md_file}")
    
    def _generate_markdown_report(self) -> str:
        """T·∫°o b√°o c√°o d·∫°ng Markdown"""
        report = []
        report.append("# üìä B√°o c√°o Ch·∫•t l∆∞·ª£ng D·ªØ li·ªáu Y t·∫ø\n")
        report.append(f"*Ng√†y ƒë√°nh gi√°: {self.quality_report['overview'].get('evaluation_date', 'N/A')}*\n")
        
        # Overview
        report.append("## 1. T·ªïng quan\n")
        overview = self.quality_report['overview']
        report.append("| Lo·∫°i d·ªØ li·ªáu | S·ªë l∆∞·ª£ng |")
        report.append("|-------------|----------|")
        report.append(f"| D·ªØ li·ªáu th√¥ (raw) | {overview.get('total_raw', 0):,} |")
        report.append(f"| D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω | {overview.get('total_processed', 0):,} |")
        report.append(f"| C√¢u h·ªèi Q&A | {overview.get('total_generated_qa', 0):,} |")
        report.append(f"| D·ªØ li·ªáu qu·ªëc t·∫ø | {overview.get('total_external', 0):,} |")
        report.append(f"| **T·ªïng c·ªông** | **{overview.get('total_all', 0):,}** |")
        report.append("")
        
        # Target check
        total = overview.get('total_all', 0)
        if total >= 50000:
            report.append(f"‚úÖ **ƒê·∫°t y√™u c·∫ßu t·ªëi thi·ªÉu 50,000 d·ªØ li·ªáu**\n")
        else:
            report.append(f"‚ö†Ô∏è **Ch∆∞a ƒë·∫°t y√™u c·∫ßu: c·∫ßn th√™m {50000 - total:,} d·ªØ li·ªáu**\n")
        
        # Raw data quality
        report.append("## 2. Ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu th√¥\n")
        raw_quality = self.quality_report.get('raw_data_quality', {})
        
        report.append("| M·ª©c ch·∫•t l∆∞·ª£ng | S·ªë l∆∞·ª£ng |")
        report.append("|---------------|----------|")
        report.append(f"| üü¢ Cao (High) | {raw_quality.get('high', 0):,} |")
        report.append(f"| üü° Trung b√¨nh (Medium) | {raw_quality.get('medium', 0):,} |")
        report.append(f"| üü† Th·∫•p (Low) | {raw_quality.get('low', 0):,} |")
        report.append(f"| üî¥ K√©m (Poor) | {raw_quality.get('poor', 0):,} |")
        report.append("")
        
        # Common issues
        if raw_quality.get('issues'):
            report.append("### C√°c v·∫•n ƒë·ªÅ ph·ªï bi·∫øn:\n")
            for issue, count in raw_quality['issues'].items():
                report.append(f"- {issue}: {count} records")
            report.append("")
        
        # QA quality
        report.append("## 3. Ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu Q&A\n")
        qa_stats = self.quality_report.get('qa_data_quality', {})
        
        if qa_stats.get('total', 0) > 0:
            report.append(f"- T·ªïng s·ªë c√¢u h·ªèi: **{qa_stats.get('total', 0):,}**")
            report.append(f"- C√¢u ƒê√∫ng: {qa_stats.get('true_count', 0):,}")
            report.append(f"- C√¢u Sai: {qa_stats.get('false_count', 0):,}")
            report.append(f"- C√≥ gi·∫£i th√≠ch: {qa_stats.get('with_explanation', 0):,}")
            report.append(f"- T·ª∑ l·ªá c√¢n b·∫±ng: {qa_stats.get('balance_ratio', 'N/A')}")
            report.append(f"- ƒêi·ªÉm ch·∫•t l∆∞·ª£ng TB: {qa_stats.get('avg_quality_score', 0):.1f}/100")
        else:
            report.append("*Ch∆∞a c√≥ d·ªØ li·ªáu Q&A*")
        report.append("")
        
        # By source
        report.append("## 4. Th·ªëng k√™ theo ngu·ªìn\n")
        source_stats = self.quality_report.get('by_source', {})
        
        if source_stats:
            report.append("| Ngu·ªìn | S·ªë l∆∞·ª£ng | Ch·∫•t l∆∞·ª£ng cao |")
            report.append("|-------|----------|----------------|")
            for source, stats in source_stats.items():
                report.append(f"| {source} | {stats['count']:,} | {stats.get('quality_percent', 0)}% |")
        report.append("")
        
        # External data
        report.append("## 5. D·ªØ li·ªáu qu·ªëc t·∫ø (ƒêi·ªÉm c·ªông)\n")
        external = self.quality_report.get('external_data', {})
        
        if external.get('total', 0) > 0:
            report.append(f"- T·ªïng s·ªë: {external.get('total', 0):,}")
            report.append(f"- ƒê√£ d·ªãch sang ti·∫øng Vi·ªát: {external.get('with_vietnamese', 0):,}")
            report.append("\nNgu·ªìn:")
            for src, count in external.get('sources', {}).items():
                report.append(f"- {src}: {count:,}")
        else:
            report.append("*Ch∆∞a c√≥ d·ªØ li·ªáu t·ª´ ngu·ªìn qu·ªëc t·∫ø*")
        report.append("")
        
        # Issues
        report.append("## 6. C√°c v·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt\n")
        issues = self.quality_report.get('issues', [])
        
        if issues:
            for issue in issues:
                severity_icon = "üî¥" if issue['severity'] == 'high' else "üü°"
                report.append(f"{severity_icon} **{issue['message']}**")
                report.append(f"   - G·ª£i √Ω: {issue['suggestion']}\n")
        else:
            report.append("‚úÖ Kh√¥ng ph√°t hi·ªán v·∫•n ƒë·ªÅ nghi√™m tr·ªçng\n")
        
        # Recommendations
        report.append("## 7. Khuy·∫øn ngh·ªã\n")
        recommendations = self.quality_report.get('recommendations', [])
        
        if recommendations:
            for i, rec in enumerate(recommendations, 1):
                report.append(f"{i}. {rec}")
        else:
            report.append("Kh√¥ng c√≥ khuy·∫øn ngh·ªã b·ªï sung.")
        
        return "\n".join(report)
    
    def print_summary(self):
        """In t√≥m t·∫Øt ra console"""
        print("\n" + "="*60)
        print("üìä B√ÅO C√ÅO CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU Y T·∫æ")
        print("="*60)
        
        overview = self.quality_report['overview']
        print(f"\nüìà T·ªîNG QUAN:")
        print(f"   - D·ªØ li·ªáu th√¥: {overview.get('total_raw', 0):,}")
        print(f"   - ƒê√£ x·ª≠ l√Ω: {overview.get('total_processed', 0):,}")
        print(f"   - C√¢u h·ªèi Q&A: {overview.get('total_generated_qa', 0):,}")
        print(f"   - D·ªØ li·ªáu qu·ªëc t·∫ø: {overview.get('total_external', 0):,}")
        print(f"   - T·ªîNG: {overview.get('total_all', 0):,}")
        
        total = overview.get('total_all', 0)
        if total >= 50000:
            print(f"\n   ‚úÖ ƒê·∫°t y√™u c·∫ßu t·ªëi thi·ªÉu 50,000")
        else:
            print(f"\n   ‚ö†Ô∏è C·∫ßn th√™m {50000 - total:,} d·ªØ li·ªáu")
        
        # Issues
        issues = self.quality_report.get('issues', [])
        if issues:
            print(f"\n‚ö†Ô∏è C√ÅC V·∫§N ƒê·ªÄ ({len(issues)}):")
            for issue in issues:
                print(f"   - {issue['message']}")
        
        print("\n" + "="*60)


def evaluate_data_quality():
    """Main function ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng"""
    evaluator = DataQualityEvaluator()
    
    # Generate report
    report = evaluator.generate_report()
    
    # Save report
    evaluator.save_report()
    
    # Print summary
    evaluator.print_summary()
    
    return report


if __name__ == "__main__":
    evaluate_data_quality()
