"""Generate True/False QA dataset from Medical Knowledge Base.

This module creates a balanced True/False QA dataset:
- TRUE samples: Correct disease-symptom/drug relationships
- FALSE samples: Incorrect pairings (disease A with entity from disease B)

Input: data/processed/kb_medical.csv
Output: data/final/medical_true_false_qa.csv

VÃ Dá»¤ CÃ‚U Tá»T (cáº§n sinh ra):
- "Ho kÃ©o dÃ i trÃªn 3 tuáº§n lÃ  triá»‡u chá»©ng thÆ°á»ng gáº·p cá»§a bá»‡nh lao phá»•i." -> TRUE
- "Metformin thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong Ä‘iá»u trá»‹ bá»‡nh Ä‘Ã¡i thÃ¡o Ä‘Æ°á»ng type 2." -> TRUE
- "Xuáº¥t tinh sá»›m lÃ  triá»‡u chá»©ng Ä‘áº·c trÆ°ng cá»§a tÄƒng huyáº¿t Ã¡p nguyÃªn phÃ¡t." -> FALSE

VÃ Dá»¤ CÃ‚U Xáº¤U (cáº§n trÃ¡nh):
- "TiÃªm phÃ²ng vaccine thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong Ä‘iá»u trá»‹ bá»‡nh Bá»‡nh ung thÆ° dáº¡ dÃ y." (láº·p chá»¯, diá»…n Ä‘áº¡t kÃ©m)
- "Bá»‡nh Bá»‡nh mÃ´ liÃªn káº¿t cÃ³ thá»ƒ gÃ¢y ra triá»‡u chá»©ng TÃ´i hiá»‡n Ä‘ang cÃ³ triá»‡u chá»©ng khá»›p liÃªn Ä‘á»‘t ngÃ³n tay bá»‹ gáº­p." (nguyÃªn cÃ¢u há»i bá»‡nh nhÃ¢n)

Author: Medical Data Mining Project
Date: 2025-11-30
"""

import pandas as pd
import random
import re
from pathlib import Path
from typing import List, Dict, Optional

# Base directories
BASE_DIR = Path(__file__).resolve().parents[2]
DATA_DIR = BASE_DIR / 'data'
PROCESSED_DIR = DATA_DIR / 'processed'
FINAL_DIR = DATA_DIR / 'final'

# Random seed for reproducibility
RANDOM_SEED = 42


def clean_disease_name(disease: str) -> str:
    """Chuáº©n hÃ³a tÃªn bá»‡nh, loáº¡i bá» tá»« 'Bá»‡nh' á»Ÿ Ä‘áº§u náº¿u cÃ³.
    
    Args:
        disease: TÃªn bá»‡nh gá»‘c
        
    Returns:
        TÃªn bá»‡nh Ä‘Ã£ chuáº©n hÃ³a (khÃ´ng cÃ³ 'Bá»‡nh' á»Ÿ Ä‘áº§u, viáº¿t thÆ°á»ng)
        
    VÃ­ dá»¥:
        "Bá»‡nh mÃ´ liÃªn káº¿t" -> "mÃ´ liÃªn káº¿t"
        "Ung ThÆ° Dáº¡ DÃ y" -> "ung thÆ° dáº¡ dÃ y"
        "bá»‡nh Tiá»ƒu ÄÆ°á»ng" -> "tiá»ƒu Ä‘Æ°á»ng"
    """
    if not disease:
        return ""
    
    disease = disease.strip()
    
    # Loáº¡i bá» "Bá»‡nh " hoáº·c "bá»‡nh " á»Ÿ Ä‘áº§u
    if disease.lower().startswith("bá»‡nh "):
        disease = disease[5:]  # Bá» 5 kÃ½ tá»± "bá»‡nh " hoáº·c "Bá»‡nh "
    
    # Strip láº¡i sau khi cáº¯t
    disease = disease.strip()
    
    # Viáº¿t thÆ°á»ng toÃ n bá»™ Ä‘á»ƒ Ä‘á»“ng nháº¥t
    disease = disease.lower()
    
    return disease


def clean_symptom(text: str) -> str:
    """LÃ m sáº¡ch chuá»—i triá»‡u chá»©ng tá»« cÃ¢u há»i bá»‡nh nhÃ¢n.
    
    Input: "TÃ´i hiá»‡n Ä‘ang cÃ³ cÃ¡c triá»‡u chá»©ng nhÆ° vÃ ng da, Ä‘au bá»¥ng vÃ  cÃ³ khá»‘i u á»Ÿ cá»•. TÃ´i cÃ³ thá»ƒ Ä‘ang bá»‹ bá»‡nh gÃ¬?"
    Output: "vÃ ng da, Ä‘au bá»¥ng vÃ  cÃ³ khá»‘i u á»Ÿ cá»•"
    
    Quy táº¯c:
    - Cáº¯t á»Ÿ Ä‘oáº¡n "TÃ´i cÃ³ thá»ƒ Ä‘ang bá»‹ bá»‡nh gÃ¬" (náº¿u cÃ³).
    - XÃ³a cÃ¡c cá»¥m má»Ÿ Ä‘áº§u "TÃ´i", "TÃ´i hiá»‡n Ä‘ang", "TÃ´i Ä‘ang", "TÃ´i hay bá»‹", "TÃ´i bá»‹".
    - Loáº¡i bá» dáº¥u cháº¥m cÃ¢u dÆ° thá»«a á»Ÿ Ä‘áº§u/cuá»‘i.
    
    Args:
        text: Chuá»—i triá»‡u chá»©ng gá»‘c
        
    Returns:
        Chuá»—i Ä‘Ã£ lÃ m sáº¡ch, hoáº·c "" náº¿u quÃ¡ ngáº¯n
    """
    if not text or not isinstance(text, str):
        return ""
    
    text = text.strip()
    
    # Cáº¯t pháº§n cÃ¢u há»i cuá»‘i (náº¿u cÃ³)
    question_patterns = [
        r'[.?!]*\s*tÃ´i cÃ³ thá»ƒ Ä‘ang bá»‹ bá»‡nh gÃ¬[.?!]*',
        r'[.?!]*\s*tÃ´i bá»‹ bá»‡nh gÃ¬[.?!]*',
        r'[.?!]*\s*Ä‘Ã¢y lÃ  bá»‡nh gÃ¬[.?!]*',
        r'[.?!]*\s*cÃ³ pháº£i tÃ´i bá»‹[^.?!]*[.?!]*',
        r'[.?!]*\s*xin há»i[^.?!]*[.?!]*$',
        r'[.?!]*\s*cho tÃ´i há»i[^.?!]*[.?!]*$',
    ]
    for pattern in question_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)
    
    # XÃ³a cÃ¡c cá»¥m má»Ÿ Ä‘áº§u
    start_patterns = [
        r'^tÃ´i hiá»‡n Ä‘ang cÃ³ cÃ¡c triá»‡u chá»©ng nhÆ°\s*',
        r'^tÃ´i hiá»‡n Ä‘ang cÃ³ triá»‡u chá»©ng\s*',
        r'^tÃ´i hiá»‡n Ä‘ang cÃ³ cÃ¡c triá»‡u chá»©ng\s*',
        r'^tÃ´i hiá»‡n Ä‘ang bá»‹\s*',
        r'^tÃ´i hiá»‡n Ä‘ang\s*',
        r'^tÃ´i Ä‘ang cáº£m tháº¥y\s*',
        r'^tÃ´i Ä‘ang bá»‹\s*',
        r'^tÃ´i Ä‘ang cÃ³\s*',
        r'^tÃ´i Ä‘ang\s*',
        r'^tÃ´i hay bá»‹\s*',
        r'^tÃ´i hay\s*',
        r'^tÃ´i bá»‹\s*',
        r'^tÃ´i cÃ³\s*',
        r'^tÃ´i\s+',
        r'^hiá»‡n Ä‘ang\s*',
        r'^Ä‘ang bá»‹\s*',
        r'^Ä‘ang\s*',
    ]
    
    for pattern in start_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)
    
    # XÃ³a "hiá»‡n Ä‘ang" á»Ÿ giá»¯a cÃ¢u (vd: "xuáº¥t tinh sá»›m vÃ  hiá»‡n Ä‘ang nÃ© trÃ¡nh")
    text = re.sub(r'\s+hiá»‡n Ä‘ang\s+', ' ', text, flags=re.IGNORECASE)
    
    # Loáº¡i bá» dáº¥u cháº¥m cÃ¢u dÆ° thá»«a á»Ÿ Ä‘áº§u/cuá»‘i
    text = re.sub(r'^[.,;:!?\s]+', '', text)
    text = re.sub(r'[.,;:!?\s]+$', '', text)
    
    # Strip vÃ  chuáº©n hÃ³a khoáº£ng tráº¯ng
    text = re.sub(r'\s+', ' ', text).strip()
    
    # Viáº¿t thÆ°á»ng chá»¯ Ä‘áº§u
    if text:
        text = text[0].lower() + text[1:] if len(text) > 1 else text.lower()
    
    # Kiá»ƒm tra Ä‘á»™ dÃ i tá»‘i thiá»ƒu vÃ  cÃ³ chá»¯ cÃ¡i tiáº¿ng Viá»‡t
    if len(text) < 10:
        return ""
    
    # Kiá»ƒm tra cÃ³ Ã­t nháº¥t má»™t chá»¯ cÃ¡i
    if not re.search(r'[a-zA-ZÃ Ã¡áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã¨Ã©áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã¬Ã­á»‰Ä©á»‹Ã²Ã³á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£Ã¹Ãºá»§Å©á»¥Æ°á»©á»«á»­á»¯á»±á»³Ã½á»·á»¹á»µÄ‘]', text, re.IGNORECASE):
        return ""
    
    return text


def is_valid_entity(text: str) -> bool:
    """Kiá»ƒm tra entity cÃ³ há»£p lá»‡ khÃ´ng.
    
    Args:
        text: Entity text
        
    Returns:
        True náº¿u há»£p lá»‡
    """
    if not text or len(text) < 10:
        return False
    
    # Pháº£i cÃ³ Ã­t nháº¥t má»™t chá»¯ cÃ¡i tiáº¿ng Viá»‡t
    if not re.search(r'[a-zA-ZÃ Ã¡áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã¨Ã©áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã¬Ã­á»‰Ä©á»‹Ã²Ã³á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£Ã¹Ãºá»§Å©á»¥Æ°á»©á»«á»­á»¯á»±á»³Ã½á»·á»¹á»µÄ‘]', text, re.IGNORECASE):
        return False
    
    return True


def filter_bad_sentences(rows: List[Dict]) -> List[Dict]:
    """Lá»c bá» cÃ¡c cÃ¢u khÃ´ng há»£p lá»‡.
    
    Loáº¡i bá» cÃ¢u cÃ³:
    - Tá»« láº·p 2 láº§n liÃªn tiáº¿p: "Bá»‡nh Bá»‡nh", "bá»‡nh bá»‡nh"
    - Chá»©a "TÃ´i cÃ³ thá»ƒ Ä‘ang bá»‹ bá»‡nh gÃ¬", "?"
    - Äá»™ dÃ i text < 30 kÃ½ tá»±
    - label="FALSE" + chá»©a "thÆ°á»ng gáº·p" (trÃ¡nh nhiá»…u)
    
    Args:
        rows: List cÃ¡c dict {"text": ..., "label": ...}
        
    Returns:
        List Ä‘Ã£ lá»c
    """
    filtered = []
    
    # Patterns Ä‘á»ƒ phÃ¡t hiá»‡n tá»« láº·p
    duplicate_patterns = [
        r'bá»‡nh\s+bá»‡nh',
        r'triá»‡u chá»©ng\s+triá»‡u chá»©ng',
        r'Ä‘iá»u trá»‹\s+Ä‘iá»u trá»‹',
    ]
    duplicate_regex = re.compile('|'.join(duplicate_patterns), re.IGNORECASE)
    
    # Patterns cÃ¢u há»i bá»‡nh nhÃ¢n (khÃ´ng pháº£i má»‡nh Ä‘á» kiáº¿n thá»©c)
    question_patterns = [
        r'tÃ´i cÃ³ thá»ƒ Ä‘ang bá»‹ bá»‡nh gÃ¬',
        r'tÃ´i bá»‹ bá»‡nh gÃ¬',
        r'\?',  # Dáº¥u há»i
    ]
    question_regex = re.compile('|'.join(question_patterns), re.IGNORECASE)
    
    for row in rows:
        text = row.get('text', '')
        label = row.get('label', '')
        
        # Kiá»ƒm tra Ä‘á»™ dÃ i
        if len(text) < 30:
            continue
        
        # Kiá»ƒm tra tá»« láº·p
        if duplicate_regex.search(text):
            continue
        
        # Kiá»ƒm tra cÃ¢u há»i bá»‡nh nhÃ¢n
        if question_regex.search(text):
            continue
        
        # Vá»›i FALSE, loáº¡i bá» cÃ¢u cÃ³ "thÆ°á»ng gáº·p" Ä‘á»ƒ trÃ¡nh nhiá»…u
        if label == 'FALSE' and 'thÆ°á»ng gáº·p' in text.lower():
            continue
        
        filtered.append(row)
    
    return filtered


def load_knowledge_base(path: Path = None) -> pd.DataFrame:
    """Load the medical knowledge base.
    
    Args:
        path: Path to kb_medical.csv. If None, uses default path.
        
    Returns:
        pd.DataFrame with knowledge base data
    """
    if path is None:
        path = PROCESSED_DIR / 'kb_medical.csv'
    
    df = pd.read_csv(path, encoding='utf-8-sig')
    
    # Filter out rows with empty entity (ICD-10 placeholders)
    df = df[df['entity'].notna() & (df['entity'] != '')]
    
    # Reset index
    df = df.reset_index(drop=True)
    
    return df


def generate_true_samples(kb: pd.DataFrame) -> List[Dict]:
    """Generate TRUE samples from knowledge base.
    
    Templates:
    - Triá»‡u chá»©ng:
        f"{entity} lÃ  triá»‡u chá»©ng thÆ°á»ng gáº·p cá»§a bá»‡nh {disease_clean}."
        f"Bá»‡nh {disease_clean} cÃ³ thá»ƒ gÃ¢y ra triá»‡u chá»©ng {entity}."
    - Thuá»‘c:
        f"{entity} thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong Ä‘iá»u trá»‹ bá»‡nh {disease_clean}."
    
    Args:
        kb: Knowledge base DataFrame
        
    Returns:
        List of dict with keys: text, label
    """
    records = []
    
    for _, row in kb.iterrows():
        disease_raw = str(row['disease']).strip()
        entity_raw = str(row['entity']).strip()
        relation = str(row['relation']).strip()
        
        if not disease_raw or not entity_raw or disease_raw == 'nan' or entity_raw == 'nan':
            continue
        
        # Chuáº©n hÃ³a disease (loáº¡i bá» "Bá»‡nh" á»Ÿ Ä‘áº§u)
        disease_clean = clean_disease_name(disease_raw)
        if not disease_clean:
            continue
        
        # Chuáº©n hÃ³a entity (lÃ m sáº¡ch cÃ¢u há»i bá»‡nh nhÃ¢n)
        entity = clean_symptom(entity_raw)
        if not is_valid_entity(entity):
            continue
        
        # Sinh cÃ¢u theo relation
        if relation == 'has_symptom':
            # Template 1: "{Entity} lÃ  triá»‡u chá»©ng thÆ°á»ng gáº·p cá»§a bá»‡nh {disease_clean}."
            # Viáº¿t hoa chá»¯ Ä‘áº§u cá»§a entity vÃ¬ Ä‘á»©ng Ä‘áº§u cÃ¢u
            entity_cap = entity[0].upper() + entity[1:] if len(entity) > 1 else entity.upper()
            text1 = f"{entity_cap} lÃ  triá»‡u chá»©ng thÆ°á»ng gáº·p cá»§a bá»‡nh {disease_clean}."
            records.append({'text': text1, 'label': 'TRUE'})
            
            # Template 2: "Bá»‡nh {disease_clean} cÃ³ thá»ƒ gÃ¢y ra triá»‡u chá»©ng {entity}."
            text2 = f"Bá»‡nh {disease_clean} cÃ³ thá»ƒ gÃ¢y ra triá»‡u chá»©ng {entity}."
            records.append({'text': text2, 'label': 'TRUE'})
            
        elif relation == 'treated_by':
            # Template: "{Entity} thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong Ä‘iá»u trá»‹ bá»‡nh {disease_clean}."
            entity_cap = entity[0].upper() + entity[1:] if len(entity) > 1 else entity.upper()
            text = f"{entity_cap} thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong Ä‘iá»u trá»‹ bá»‡nh {disease_clean}."
            records.append({'text': text, 'label': 'TRUE'})
    
    return records


def generate_false_samples(kb: pd.DataFrame, n_samples: int) -> List[Dict]:
    """Generate FALSE samples by pairing disease A with entity from disease B.
    
    Sá»­ dá»¥ng template khÃ¡c vá»›i TRUE Ä‘á»ƒ trÃ¡nh nhiá»…u:
    - Triá»‡u chá»©ng: "Bá»‡nh {disease} cÃ³ thá»ƒ gÃ¢y ra triá»‡u chá»©ng {entity}."
    - Thuá»‘c: "{entity} Ä‘Æ°á»£c sá»­ dá»¥ng trong Ä‘iá»u trá»‹ bá»‡nh {disease}."
    
    Args:
        kb: Knowledge base DataFrame
        n_samples: Number of FALSE samples to generate
        
    Returns:
        List of dict with keys: text, label
    """
    random.seed(RANDOM_SEED)
    
    # Separate symptoms and drugs
    symptoms_kb = kb[kb['relation'] == 'has_symptom'].copy()
    drugs_kb = kb[kb['relation'] == 'treated_by'].copy()
    
    # Clean all diseases and entities
    symptom_diseases = []
    symptom_entities = []
    symptom_map = {}  # disease -> set of entities
    
    for _, row in symptoms_kb.iterrows():
        disease_clean = clean_disease_name(str(row['disease']).strip())
        entity = clean_symptom(str(row['entity']).strip())
        
        if disease_clean and is_valid_entity(entity):
            if disease_clean not in symptom_map:
                symptom_map[disease_clean] = set()
                symptom_diseases.append(disease_clean)
            symptom_map[disease_clean].add(entity)
            if entity not in symptom_entities:
                symptom_entities.append(entity)
    
    drug_diseases = []
    drug_entities = []
    drug_map = {}  # disease -> set of entities
    
    for _, row in drugs_kb.iterrows():
        disease_clean = clean_disease_name(str(row['disease']).strip())
        entity = clean_symptom(str(row['entity']).strip())
        
        if disease_clean and is_valid_entity(entity):
            if disease_clean not in drug_map:
                drug_map[disease_clean] = set()
                drug_diseases.append(disease_clean)
            drug_map[disease_clean].add(entity)
            if entity not in drug_entities:
                drug_entities.append(entity)
    
    records = []
    used_pairs = set()
    
    # Calculate proportions
    n_symptom_false = int(n_samples * 0.9)  # 90% triá»‡u chá»©ng
    n_drug_false = n_samples - n_symptom_false
    
    # Generate FALSE symptom samples
    attempts = 0
    max_attempts = n_symptom_false * 20
    
    while len([r for r in records if 'triá»‡u chá»©ng' in r['text']]) < n_symptom_false and attempts < max_attempts:
        attempts += 1
        
        if not symptom_diseases or not symptom_entities:
            break
        
        disease = random.choice(symptom_diseases)
        entity = random.choice(symptom_entities)
        
        # Skip if this is a TRUE relationship
        if disease in symptom_map and entity in symptom_map[disease]:
            continue
        
        pair_key = (disease, entity, 'symptom')
        if pair_key in used_pairs:
            continue
        used_pairs.add(pair_key)
        
        # Template cho FALSE: khÃ´ng dÃ¹ng "thÆ°á»ng gáº·p"
        # disease Ä‘Ã£ lÃ  lowercase tá»« clean_disease_name
        text = f"Bá»‡nh {disease} cÃ³ thá»ƒ gÃ¢y ra triá»‡u chá»©ng {entity}."
        records.append({'text': text, 'label': 'FALSE'})
    
    # Generate FALSE drug samples
    attempts = 0
    max_attempts = n_drug_false * 20
    
    while len([r for r in records if 'Ä‘iá»u trá»‹' in r['text']]) < n_drug_false and attempts < max_attempts:
        attempts += 1
        
        if not drug_diseases or not drug_entities:
            break
        
        disease = random.choice(drug_diseases)
        entity = random.choice(drug_entities)
        
        # Skip if this is a TRUE relationship
        if disease in drug_map and entity in drug_map[disease]:
            continue
        
        pair_key = (disease, entity, 'drug')
        if pair_key in used_pairs:
            continue
        used_pairs.add(pair_key)
        
        # Template cho FALSE: khÃ´ng dÃ¹ng "thÆ°á»ng"
        # Viáº¿t hoa chá»¯ Ä‘áº§u cá»§a entity vÃ¬ Ä‘á»©ng Ä‘áº§u cÃ¢u
        entity_cap = entity[0].upper() + entity[1:] if len(entity) > 1 else entity.upper()
        text = f"{entity_cap} Ä‘Æ°á»£c sá»­ dá»¥ng trong Ä‘iá»u trá»‹ bá»‡nh {disease}."
        records.append({'text': text, 'label': 'FALSE'})
    
    return records


def create_true_false_dataset(kb: pd.DataFrame) -> pd.DataFrame:
    """Create balanced True/False QA dataset.
    
    Args:
        kb: Knowledge base DataFrame
        
    Returns:
        pd.DataFrame with columns: STT, Má»‡nh Ä‘á» CÃ¢u há»i, ÄÃ¡p Ã¡n
    """
    print("\n" + "-" * 40)
    print("1. Sinh cÃ¢u TRUE")
    print("-" * 40)
    
    # Generate TRUE samples
    true_records = generate_true_samples(kb)
    print(f"   âœ“ ÄÃ£ sinh {len(true_records)} cÃ¢u TRUE (trÆ°á»›c lá»c)")
    
    print("\n" + "-" * 40)
    print("2. Sinh cÃ¢u FALSE")
    print("-" * 40)
    
    # Generate FALSE samples (approximately equal to TRUE)
    n_false_target = len(true_records)
    false_records = generate_false_samples(kb, n_false_target)
    print(f"   âœ“ ÄÃ£ sinh {len(false_records)} cÃ¢u FALSE (trÆ°á»›c lá»c)")
    
    print("\n" + "-" * 40)
    print("3. Lá»c cÃ¢u khÃ´ng há»£p lá»‡")
    print("-" * 40)
    
    # Combine all records
    all_records = true_records + false_records
    print(f"   Tá»•ng sá»‘ trÆ°á»›c khi lá»c: {len(all_records)}")
    
    # Filter bad sentences
    filtered_records = filter_bad_sentences(all_records)
    print(f"   Tá»•ng sá»‘ sau khi lá»c: {len(filtered_records)}")
    print(f"   ÄÃ£ loáº¡i bá»: {len(all_records) - len(filtered_records)} cÃ¢u")
    
    print("\n" + "-" * 40)
    print("4. Gá»™p vÃ  shuffle dá»¯ liá»‡u")
    print("-" * 40)
    
    # Create DataFrame
    df_combined = pd.DataFrame(filtered_records)
    
    # Remove duplicates
    df_combined = df_combined.drop_duplicates(subset=['text'])
    print(f"   âœ“ Tá»•ng sá»‘ sau khi loáº¡i trÃ¹ng: {len(df_combined)}")
    
    # Shuffle
    df_combined = df_combined.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)
    print(f"   âœ“ ÄÃ£ shuffle dá»¯ liá»‡u")
    
    # Add STT column (1-indexed)
    df_combined['STT'] = range(1, len(df_combined) + 1)
    
    # Rename columns
    df_combined = df_combined.rename(columns={
        'text': 'Má»‡nh Ä‘á» CÃ¢u há»i (VIETNAMESE TEXT ONLY)',
        'label': 'ÄÃ¡p Ã¡n (TRUE/FALSE)'
    })
    
    # Reorder columns
    df_combined = df_combined[['STT', 'Má»‡nh Ä‘á» CÃ¢u há»i (VIETNAMESE TEXT ONLY)', 'ÄÃ¡p Ã¡n (TRUE/FALSE)']]
    
    return df_combined


def print_statistics(df: pd.DataFrame) -> None:
    """Print statistics about the dataset.
    
    Args:
        df: Final dataset DataFrame
    """
    print("\n" + "=" * 60)
    print("THá»NG KÃŠ DATASET TRUE/FALSE QA")
    print("=" * 60)
    
    total = len(df)
    n_true = len(df[df['ÄÃ¡p Ã¡n (TRUE/FALSE)'] == 'TRUE'])
    n_false = len(df[df['ÄÃ¡p Ã¡n (TRUE/FALSE)'] == 'FALSE'])
    
    print(f"\nğŸ“Š Tá»•ng sá»‘ dÃ²ng: {total}")
    print(f"ğŸ“Š Sá»‘ cÃ¢u TRUE: {n_true} ({n_true/total*100:.1f}%)")
    print(f"ğŸ“Š Sá»‘ cÃ¢u FALSE: {n_false} ({n_false/total*100:.1f}%)")
    
    print("\nğŸ“‹ Máº«u dá»¯ liá»‡u (10 dÃ²ng Ä‘áº§u):")
    print(df.head(10).to_string())
    
    print("\nğŸ“‹ Máº«u dá»¯ liá»‡u (10 dÃ²ng cuá»‘i):")
    print(df.tail(10).to_string())


def main():
    """Main function to generate True/False QA dataset."""
    print("=" * 60)
    print("Táº O DATASET TRUE/FALSE QA Tá»ª KNOWLEDGE BASE")
    print("=" * 60)
    
    # Load knowledge base
    print("\n" + "-" * 40)
    print("0. Äá»c Knowledge Base")
    print("-" * 40)
    
    kb = load_knowledge_base()
    print(f"   âœ“ ÄÃ£ Ä‘á»c {len(kb)} dÃ²ng tá»« kb_medical.csv")
    print(f"   âœ“ Sá»‘ dÃ²ng cÃ³ relation 'has_symptom': {len(kb[kb['relation'] == 'has_symptom'])}")
    print(f"   âœ“ Sá»‘ dÃ²ng cÃ³ relation 'treated_by': {len(kb[kb['relation'] == 'treated_by'])}")
    
    # Create dataset
    df = create_true_false_dataset(kb)
    
    # Print statistics
    print_statistics(df)
    
    # Save to CSV
    print("\n" + "-" * 40)
    print("5. LÆ°u file")
    print("-" * 40)
    
    # Create final directory if not exists
    FINAL_DIR.mkdir(parents=True, exist_ok=True)
    
    output_path = FINAL_DIR / 'medical_true_false_qa.csv'
    df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"   âœ“ ÄÃ£ lÆ°u vÃ o: {output_path}")
    
    return df


if __name__ == '__main__':
    df = main()
    
    print("\n" + "=" * 60)
    print("HOÃ€N Táº¤T!")
    print("=" * 60)
