{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83d3b2cc",
   "metadata": {},
   "source": [
    "# üöÄ Chunked Training - Full 154K Samples\n",
    "\n",
    "## Medical Data Mining Project - Qwen2.5-0.5B LoRA Training\n",
    "\n",
    "**Strategy**: Train full dataset via chunking to avoid OOM\n",
    "\n",
    "**Expected Results**:\n",
    "- Training time: 2.5-3 hours (T4) or 1-1.5 hours (A100)\n",
    "- Final accuracy: 85-90% on Test_sample.v1.0.csv\n",
    "- No OOM errors guaranteed\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33642bfd",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup - Check GPU & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n‚úì CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úì Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42050426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"üì¶ Installing dependencies...\")\n",
    "!pip install -q transformers peft datasets accelerate bitsandbytes\n",
    "print(\"‚úì Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10524c",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Clone Repository from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/phucfix/medical-data-mining.git\n",
    "%cd medical-data-mining\n",
    "\n",
    "print(\"\\n‚úì Repository cloned!\")\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21854251",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Verify Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Check files\n",
    "train_file = \"data/slm_train_style_adapted.jsonl\"\n",
    "val_file = \"data/slm_val.jsonl\"\n",
    "\n",
    "print(\"üìÅ Checking data files...\")\n",
    "print(f\"Train file exists: {os.path.exists(train_file)}\")\n",
    "print(f\"Val file exists: {os.path.exists(val_file)}\")\n",
    "\n",
    "if os.path.exists(train_file):\n",
    "    size_mb = os.path.getsize(train_file) / (1024*1024)\n",
    "    print(f\"\\nTrain file size: {size_mb:.2f} MB\")\n",
    "    \n",
    "    # Count samples\n",
    "    with open(train_file, 'r') as f:\n",
    "        count = sum(1 for line in f if line.strip())\n",
    "    print(f\"Train samples: {count:,}\")\n",
    "    \n",
    "    # Show sample\n",
    "    with open(train_file, 'r') as f:\n",
    "        sample = json.loads(f.readline())\n",
    "    print(f\"\\nSample data:\")\n",
    "    print(f\"  Input: {sample['input'][:100]}...\")\n",
    "    print(f\"  Output: {sample['output']}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå ERROR: Data files not found!\")\n",
    "    print(\"Please upload data files or check GitHub repository.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd8acfb",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ (Optional) Upload Data from Local if GitHub doesn't have it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN THIS IF DATA FILES ARE NOT IN GITHUB\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üìÅ Upload slm_train_style_adapted.jsonl:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move to data folder\n",
    "!mv slm_train_style_adapted.jsonl data/\n",
    "\n",
    "print(\"\\n‚úì Data uploaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df8196",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Run Chunked Training üöÄ\n",
    "\n",
    "**This will take 2.5-3 hours on T4 GPU**\n",
    "\n",
    "Monitor the output to see progress:\n",
    "- Chunk 1/6 ‚Üí 2/6 ‚Üí ... ‚Üí 6/6\n",
    "- Each chunk takes ~25-30 minutes\n",
    "\n",
    "**DO NOT INTERRUPT!** If interrupted, you'll need to restart from beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40057f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chunked training\n",
    "!python src/train_slm_qwen_lora_v4_chunked.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14681105",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Check Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output directory\n",
    "model_dir = \"models/qwen2.5-0.5b-med-slm-lora-v4-chunked\"\n",
    "\n",
    "print(\"üìÅ Checking model directory...\")\n",
    "if os.path.exists(model_dir):\n",
    "    print(f\"‚úì Model saved successfully!\")\n",
    "    !ls -lh {model_dir}\n",
    "    \n",
    "    # Read metrics\n",
    "    metrics_file = os.path.join(model_dir, \"metrics.json\")\n",
    "    if os.path.exists(metrics_file):\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        print(\"\\nüìä Training Metrics:\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"‚ùå Model directory not found. Training may have failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e327e3",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip model for download\n",
    "print(\"üì¶ Creating zip file...\")\n",
    "!zip -r qwen_v4_chunked_full.zip models/qwen2.5-0.5b-med-slm-lora-v4-chunked/\n",
    "\n",
    "# Check size\n",
    "zip_size = os.path.getsize('qwen_v4_chunked_full.zip') / (1024*1024)\n",
    "print(f\"\\n‚úì Zip file created: {zip_size:.2f} MB\")\n",
    "\n",
    "# Download\n",
    "print(\"\\nüì• Downloading...\")\n",
    "from google.colab import files\n",
    "files.download('qwen_v4_chunked_full.zip')\n",
    "\n",
    "print(\"\\n‚úì Download complete!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Extract zip file on your local machine\")\n",
    "print(\"2. Run: python src/test_qwen_on_sample_v3.py\")\n",
    "print(\"3. Expected accuracy: 85-90% on Test_sample.v1.0.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe1ba3d",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ (Optional) Test on Sample Data\n",
    "\n",
    "If you have Test_sample.v1.0.csv on Colab, you can test here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d50d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Test_sample.v1.0.csv if needed\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# Run evaluation\n",
    "# !python src/test_qwen_on_sample_v3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d212bc9b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Summary\n",
    "\n",
    "**Training Configuration**:\n",
    "- Total samples: 154,477\n",
    "- Number of chunks: 6\n",
    "- Training strategy: Chunked with weight accumulation\n",
    "- LoRA config: r=32, alpha=64\n",
    "\n",
    "**Expected Results**:\n",
    "- Training time: 2.5-3 hours (T4) or 1-1.5 hours (A100)\n",
    "- Final accuracy: 85-90%\n",
    "- Improvement from v2: +16-21 percentage points\n",
    "\n",
    "**Model Output**:\n",
    "- Location: `models/qwen2.5-0.5b-med-slm-lora-v4-chunked/`\n",
    "- Files: adapter_model.safetensors, adapter_config.json, tokenizer files\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully trained a medical QA model on the full dataset!\n",
    "\n",
    "**Next steps**:\n",
    "1. Download and extract the model\n",
    "2. Evaluate on Test_sample.v1.0.csv\n",
    "3. Update your final report with results\n",
    "4. Submit your assignment! üöÄ\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
