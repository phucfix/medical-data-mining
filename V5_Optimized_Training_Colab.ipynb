{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc02363a",
   "metadata": {},
   "source": [
    "# üöÄ V5 Optimized Training - Qwen2.5-0.5B\n",
    "\n",
    "## Improvements:\n",
    "- ‚úÖ **3 epochs** (vs 1 epoch in v4)\n",
    "- ‚úÖ **Lower LR** (5e-6 vs 2e-5) - h·ªçc ch·∫≠m, ·ªïn ƒë·ªãnh h∆°n\n",
    "- ‚úÖ **Cosine scheduler** v·ªõi warmup d√†i h∆°n\n",
    "- ‚úÖ **LoRA rank 64** (vs 32) - model capacity cao h∆°n\n",
    "- ‚úÖ **Gradient clipping** - stability\n",
    "- ‚úÖ **Smart eval** every 2000 steps\n",
    "\n",
    "## Expected Results:\n",
    "- **Target**: 60-65% accuracy (+9-14% vs v4's 51%)\n",
    "- **Training time**: ~4-5 hours on T4 GPU\n",
    "- **Memory**: Fits in T4 15GB VRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2d099",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e92674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1dffe5",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33774fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets peft accelerate bitsandbytes sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebcb208",
   "metadata": {},
   "source": [
    "## Step 3: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/phucfix/medical-data-mining.git\n",
    "%cd medical-data-mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f6b3ae",
   "metadata": {},
   "source": [
    "## Step 4: Pull Latest Code (if already cloned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you already cloned and need to update\n",
    "# %cd medical-data-mining\n",
    "# !git pull origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b499c63",
   "metadata": {},
   "source": [
    "## Step 5: Verify Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b7acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Check training data\n",
    "with open('data/slm_train_style_adapted.jsonl', 'r') as f:\n",
    "    train_data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "print(f\"üìä Training samples: {len(train_data):,}\")\n",
    "print(f\"\\nüìù Sample data:\")\n",
    "print(json.dumps(train_data[0], indent=2, ensure_ascii=False))\n",
    "\n",
    "# Check validation data if exists\n",
    "try:\n",
    "    with open('data/slm_val.jsonl', 'r') as f:\n",
    "        val_data = [json.loads(line) for line in f if line.strip()]\n",
    "    print(f\"\\n‚úÖ Validation samples: {len(val_data):,}\")\n",
    "except:\n",
    "    print(\"\\n‚ö†Ô∏è  No validation data found (will train without eval)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29f1e0",
   "metadata": {},
   "source": [
    "## Step 6: Start Training üî•\n",
    "\n",
    "**IMPORTANT**: This will take ~4-5 hours on T4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66121590",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/train_slm_qwen_lora_v5_optimized.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727102f4",
   "metadata": {},
   "source": [
    "## Step 7: Check Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd47d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/qwen2.5-0.5b-med-slm-lora-v5-optimized/metrics.json', 'r') as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(\"üìä Training Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608e4784",
   "metadata": {},
   "source": [
    "## Step 8: Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2916289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the model\n",
    "!zip -r qwen2.5-0.5b-med-slm-lora-v5-optimized.zip models/qwen2.5-0.5b-med-slm-lora-v5-optimized\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download('qwen2.5-0.5b-med-slm-lora-v5-optimized.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c7260c",
   "metadata": {},
   "source": [
    "## Step 9: Test Model on Test_sample.v1.0.csv üß™\n",
    "\n",
    "Test the trained model and compare with v4-chunked baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test script\n",
    "!python src/test_qwen_on_sample_v4.py --version v5-optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad68892f",
   "metadata": {},
   "source": [
    "## Step 10: Analyze Test Results üìä\n",
    "\n",
    "Load and visualize the test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Load test results\n",
    "with open('data/test_sample_v5-optimized_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Display metrics\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ V5 OPTIMIZED TEST RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìä Overall Performance:\")\n",
    "print(f\"   Accuracy: {results['accuracy']:.2%}\")\n",
    "print(f\"   Correct: {results['correct']}/{results['total']}\")\n",
    "print(f\"\\nüìà Detailed Metrics:\")\n",
    "print(f\"   Precision: {results['precision']:.4f}\")\n",
    "print(f\"   Recall: {results['recall']:.4f}\")\n",
    "print(f\"   F1-Score: {results['f1']:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\nüî¢ Confusion Matrix:\")\n",
    "cm = results['confusion_matrix']\n",
    "print(f\"   True Positives:  {cm['TP']}\")\n",
    "print(f\"   False Positives: {cm['FP']}\")\n",
    "print(f\"   True Negatives:  {cm['TN']}\")\n",
    "print(f\"   False Negatives: {cm['FN']}\")\n",
    "\n",
    "# Prediction Distribution\n",
    "pred_dist = results['prediction_distribution']\n",
    "actual_dist = results['actual_distribution']\n",
    "print(f\"\\nüìä Prediction Distribution:\")\n",
    "print(f\"   Predicted TRUE:  {pred_dist['TRUE']} ({pred_dist['TRUE']/results['total']*100:.1f}%)\")\n",
    "print(f\"   Predicted FALSE: {pred_dist['FALSE']} ({pred_dist['FALSE']/results['total']*100:.1f}%)\")\n",
    "print(f\"\\nüìä Actual Distribution:\")\n",
    "print(f\"   Actual TRUE:  {actual_dist['TRUE']} ({actual_dist['TRUE']/results['total']*100:.1f}%)\")\n",
    "print(f\"   Actual FALSE: {actual_dist['FALSE']} ({actual_dist['FALSE']/results['total']*100:.1f}%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm_matrix = [[cm['TP'], cm['FP']], [cm['FN'], cm['TN']]]\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Pred TRUE', 'Pred FALSE'],\n",
    "            yticklabels=['Actual TRUE', 'Actual FALSE'])\n",
    "plt.title(f'V5 Optimized - Confusion Matrix\\nAccuracy: {results[\"accuracy\"]:.2%}')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig('v5_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\n‚úÖ Confusion matrix saved as 'v5_confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca782e40",
   "metadata": {},
   "source": [
    "## Step 11: Compare v4 vs v5 Performance üìà\n",
    "\n",
    "Compare the improvements from v4-chunked to v5-optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98794713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison data (v4-chunked baseline)\n",
    "v4_accuracy = 0.5120  # 51.20%\n",
    "v4_precision = 0.5308\n",
    "v4_recall = 0.6899\n",
    "v4_f1 = 0.6000\n",
    "\n",
    "# v5 results\n",
    "v5_accuracy = results['accuracy']\n",
    "v5_precision = results['precision']\n",
    "v5_recall = results['recall']\n",
    "v5_f1 = results['f1']\n",
    "\n",
    "# Calculate improvements\n",
    "acc_improvement = (v5_accuracy - v4_accuracy) * 100\n",
    "prec_improvement = (v5_precision - v4_precision) * 100\n",
    "recall_improvement = (v5_recall - v4_recall) * 100\n",
    "f1_improvement = (v5_f1 - v4_f1) * 100\n",
    "\n",
    "# Display comparison\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä V4 vs V5 COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{'Metric':<15} {'v4-chunked':<15} {'v5-optimized':<15} {'Improvement':<15}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Accuracy':<15} {v4_accuracy:<15.2%} {v5_accuracy:<15.2%} {acc_improvement:>+13.2f}%\")\n",
    "print(f\"{'Precision':<15} {v4_precision:<15.4f} {v5_precision:<15.4f} {prec_improvement:>+13.2f}%\")\n",
    "print(f\"{'Recall':<15} {v4_recall:<15.4f} {v5_recall:<15.4f} {recall_improvement:>+13.2f}%\")\n",
    "print(f\"{'F1-Score':<15} {v4_f1:<15.4f} {v5_f1:<15.4f} {f1_improvement:>+13.2f}%\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart comparison\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "v4_values = [v4_accuracy*100, v4_precision*100, v4_recall*100, v4_f1*100]\n",
    "v5_values = [v5_accuracy*100, v5_precision*100, v5_recall*100, v5_f1*100]\n",
    "\n",
    "x = range(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar([i - width/2 for i in x], v4_values, width, label='v4-chunked', color='skyblue')\n",
    "axes[0].bar([i + width/2 for i in x], v5_values, width, label='v5-optimized', color='lightcoral')\n",
    "axes[0].set_ylabel('Score (%)')\n",
    "axes[0].set_title('V4 vs V5 Performance Comparison')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics, rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (v4, v5) in enumerate(zip(v4_values, v5_values)):\n",
    "    axes[0].text(i - width/2, v4 + 1, f'{v4:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "    axes[0].text(i + width/2, v5 + 1, f'{v5:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Improvement chart\n",
    "improvements = [acc_improvement, prec_improvement, recall_improvement, f1_improvement]\n",
    "colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
    "axes[1].barh(metrics, improvements, color=colors, alpha=0.7)\n",
    "axes[1].set_xlabel('Improvement (%)')\n",
    "axes[1].set_title('V5 Improvements over V4')\n",
    "axes[1].axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, imp in enumerate(improvements):\n",
    "    axes[1].text(imp, i, f' {imp:+.2f}%', va='center', \n",
    "                ha='left' if imp > 0 else 'right', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('v4_vs_v5_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\n‚úÖ Comparison chart saved as 'v4_vs_v5_comparison.png'\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nüéØ SUMMARY:\")\n",
    "if v5_accuracy >= 0.60:\n",
    "    print(f\"   ‚úÖ SUCCESS! Achieved {v5_accuracy:.2%} accuracy (target: 60-65%)\")\n",
    "    print(f\"   ‚úÖ Improved by {acc_improvement:+.2f}% from v4's {v4_accuracy:.2%}\")\n",
    "elif v5_accuracy > v4_accuracy:\n",
    "    print(f\"   ‚ö†Ô∏è  Partial success: {v5_accuracy:.2%} accuracy\")\n",
    "    print(f\"   üìà Improved by {acc_improvement:+.2f}% but below 60% target\")\n",
    "else:\n",
    "    print(f\"   ‚ùå No improvement: {v5_accuracy:.2%} vs v4's {v4_accuracy:.2%}\")\n",
    "    print(f\"   üìâ Need to investigate training issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78913d8c",
   "metadata": {},
   "source": [
    "## Step 12: Error Analysis üîç\n",
    "\n",
    "Analyze prediction errors to understand model weaknesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf43e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data with predictions\n",
    "import csv\n",
    "\n",
    "test_data = []\n",
    "with open('Test_sample.v1.0.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        test_data.append(row)\n",
    "\n",
    "# Match predictions from results file\n",
    "predictions = results['predictions']\n",
    "\n",
    "# Analyze errors\n",
    "errors = []\n",
    "for i, (sample, pred) in enumerate(zip(test_data, predictions)):\n",
    "    actual = sample['answer']\n",
    "    if pred != actual:\n",
    "        errors.append({\n",
    "            'index': i,\n",
    "            'question': sample['question'],\n",
    "            'actual': actual,\n",
    "            'predicted': pred,\n",
    "            'error_type': f\"False {'Positive' if pred == 'ƒê√∫ng' else 'Negative'}\"\n",
    "        })\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"üîç ERROR ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüìä Total Errors: {len(errors)} / {len(test_data)} ({len(errors)/len(test_data)*100:.1f}%)\")\n",
    "\n",
    "# Error type distribution\n",
    "false_positives = sum(1 for e in errors if e['error_type'] == 'False Positive')\n",
    "false_negatives = sum(1 for e in errors if e['error_type'] == 'False Negative')\n",
    "\n",
    "print(f\"\\nüìà Error Distribution:\")\n",
    "print(f\"   False Positives: {false_positives} ({false_positives/len(errors)*100:.1f}%)\")\n",
    "print(f\"   False Negatives: {false_negatives} ({false_negatives/len(errors)*100:.1f}%)\")\n",
    "\n",
    "# Show sample errors\n",
    "print(f\"\\nüî¥ Sample False Positives (predicted ƒê√∫ng, actually Sai):\")\n",
    "print(\"-\" * 80)\n",
    "fp_samples = [e for e in errors if e['error_type'] == 'False Positive'][:5]\n",
    "for i, err in enumerate(fp_samples, 1):\n",
    "    print(f\"\\n{i}. Question: {err['question'][:100]}...\")\n",
    "    print(f\"   Predicted: {err['predicted']} | Actual: {err['actual']}\")\n",
    "\n",
    "print(f\"\\nüî¥ Sample False Negatives (predicted Sai, actually ƒê√∫ng):\")\n",
    "print(\"-\" * 80)\n",
    "fn_samples = [e for e in errors if e['error_type'] == 'False Negative'][:5]\n",
    "for i, err in enumerate(fn_samples, 1):\n",
    "    print(f\"\\n{i}. Question: {err['question'][:100]}...\")\n",
    "    print(f\"   Predicted: {err['predicted']} | Actual: {err['actual']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Save detailed error analysis\n",
    "error_df = pd.DataFrame(errors)\n",
    "error_df.to_csv('v5_error_analysis.csv', index=False, encoding='utf-8')\n",
    "print(f\"\\n‚úÖ Detailed error analysis saved to 'v5_error_analysis.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0268e6",
   "metadata": {},
   "source": [
    "## Expected Improvements\n",
    "\n",
    "| Version | Epochs | LR | LoRA Rank | Accuracy | Notes |\n",
    "|---------|--------|-----|-----------|----------|-------|\n",
    "| v4-chunked | 1 | 2e-5 | 32 | 51% | Baseline |\n",
    "| v5-optimized | 3 | 5e-6 | 64 | **60-65%** | +9-14% expected |\n",
    "\n",
    "## Key Changes:\n",
    "1. **More training**: 3 epochs vs 1 epoch ‚Üí better learning\n",
    "2. **Stable learning**: Lower LR (5e-6) + cosine scheduler ‚Üí avoid overfitting\n",
    "3. **More capacity**: LoRA rank 64 ‚Üí can learn more complex patterns\n",
    "4. **Better regularization**: Gradient clipping + longer warmup"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
